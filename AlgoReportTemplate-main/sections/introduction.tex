Hoy en día, en la era de la tecnología, la \textbf{calidad y eficiencia de los programas computacionales} ha crecido enormemente. Con el avance tecnológico, el incremento en la cantidad de datos y la complejidad de los procesos, es fundamental contar con métodos para consultar, organizar y manejar esta información de manera eficiente. En este contexto, el campo de Análisis y Diseño de Algoritmos en Ciencias de la Computación cobra especial relevancia, ya que permite abordar la resolución de problemas complejos y la creación de programas optimizados que puedan ejecutarse en tiempos razonables y con un consumo de memoria reducido.

\epigraph{\textit{``... However, Generalized Levenshtein Distance  is not suitable for certain applications such as recognizing noisy subsequences and skeletal images since it lacks an appropriate normalization with respect to the lengths of the compared strings.''}}{--- \citeauthor{yujian2007normalized}, \citeyear{yujian2007normalized} \cite{yujian2007normalized}}

Un problema recurrente en este campo es el cálculo de la \textbf{distancia mínima de edición}, ampliamente utilizado en aplicaciones como el \textbf{procesamiento de lenguaje natural, la recuperación de información, la biología computacional y la inteligencia artificial}. En estos casos, la necesidad de comparar y procesar cadenas de texto de manera precisa y eficiente es clave para obtener resultados de calidad. El cálculo de la distancia mínima de edición, además de ser una tarea común, es esencial en estos ámbitos, ya que permite medir la similitud entre dos secuencias mediante la transformación de una en otra ~\cite{yujian2007normalized,moyotl2016metodo}.

En este documento se \textbf{presentará la implementación de dos algoritmos para calcular la distancia mínima de edición entre dos cadenas con costos variables dependiendo de los caracteres}, aplicando dos enfoques: \textbf{fuerza bruta} y \textbf{programación dinámica}. Ambos algoritmos incorporan operaciones de \textbf{inserción, eliminación, sustitución y transposición} con costos variables, lo cual aumenta la complejidad y utilidad del cálculo, se utilizará la implementacion de distancia de Levenshtein como guía.

El algoritmo de \textbf{fuerza bruta} explora todas las posibles transformaciones de manera exhaustiva, y aunque es un enfoque simple, su tiempo de ejecución crece exponencialmente conforme aumenta el tamaño de las cadenas, lo que lo convierte en una solución viable solo para casos de pequeña escala. Por otro lado, el algoritmo de \textbf{programación dinámica} optimiza la búsqueda de soluciones almacenando los resultados de subproblemas ya resueltos, lo cual reduce la cantidad de operaciones necesarias para obtener el resultado final. Sin embargo, esta optimización implica un mayor consumo de memoria, dado que es necesario almacenar los subproblemas en una estructura de datos.

Este estudio se realiza para \textbf{evaluar la eficiencia de ambos métodos}; por tanto, se analizarán el \textbf{tiempo de ejecución} y el \textbf{uso de memoria} en diferentes pares de palabras con diversas características. Se documentarán las implementaciones realizadas y se presentarán los pros y contras de ambos algoritmos de manera gráfica. De esta forma, se busca ayudar al lector a comprender las características de cada algoritmo en función de la entrada que reciben, así como la cantidad de operaciones necesarias para obtener una solución.


% Autor
% Luis Zegarra Stuardo
% 202073628-6
% Tarea 2 y 3
% Algoritmos y Complejidad 2024-2